{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"46ac0b18","cell_type":"code","source":"import torch\nfrom PIL import Image\nfrom transformers import CLIPProcessor, CLIPModel\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T13:13:13.968927Z","iopub.execute_input":"2025-04-22T13:13:13.969231Z","iopub.status.idle":"2025-04-22T13:13:46.288114Z","shell.execute_reply.started":"2025-04-22T13:13:13.969204Z","shell.execute_reply":"2025-04-22T13:13:46.287184Z"}},"outputs":[{"name":"stderr","text":"2025-04-22 13:13:31.092195: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745327611.340214      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745327611.416803      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"id":"2cc929c5","cell_type":"code","source":"# Load CLIP model from Hugging Face\nmodel_name = \"openai/clip-vit-base-patch32\"\nmodel = CLIPModel.from_pretrained(model_name)\nprocessor = CLIPProcessor.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T13:14:01.639380Z","iopub.execute_input":"2025-04-22T13:14:01.640275Z","iopub.status.idle":"2025-04-22T13:14:15.317442Z","shell.execute_reply.started":"2025-04-22T13:14:01.640245Z","shell.execute_reply":"2025-04-22T13:14:15.316362Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47b79bd053504a65b232229b2250c31c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5652ba951d374c378ef7edea1a0c3e44"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c32ddce80cd48848d0acf00cf1bd3d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7c3e44d536542fe83d4c15a84fa4fe7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfb2a87b114647e19a02e0d2c46a655d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/862k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1005026be3e4da0987aeb6ad5f78076"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67f342565d774f12ba55b6259dc11e63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.22M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fcbd98bbc37458ab9630c817a9cff79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cd114629a34407eae387c450fd795db"}},"metadata":{}}],"execution_count":2},{"id":"23339a05","cell_type":"code","source":"# path within Kaggle for Train the model \nimage_folder = \"/kaggle/input/solesensei_bdd100k/bdd100k/bdd100k/images/10k/train/\"\nsample_image = os.path.join(image_folder, \"/kaggle/input/solesensei_bdd100k/bdd100k/bdd100k/images/10k/train/0004a4c0-d4dff0ad.jpg\")\nimage = Image.open(sample_image)\nimage.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-22T13:18:16.294133Z","iopub.execute_input":"2025-04-22T13:18:16.294448Z","iopub.status.idle":"2025-04-22T13:18:16.692731Z","shell.execute_reply.started":"2025-04-22T13:18:16.294424Z","shell.execute_reply":"2025-04-22T13:18:16.691747Z"}},"outputs":[{"name":"stderr","text":"Error: no \"view\" mailcap rules found for type \"image/png\"\n/usr/bin/xdg-open: 882: www-browser: not found\n/usr/bin/xdg-open: 882: links2: not found\n/usr/bin/xdg-open: 882: elinks: not found\n/usr/bin/xdg-open: 882: links: not found\n/usr/bin/xdg-open: 882: lynx: not found\n/usr/bin/xdg-open: 882: w3m: not found\nxdg-open: no method available for opening '/tmp/tmpijzkjzff.PNG'\n","output_type":"stream"}],"execution_count":7},{"id":"cd1b69a0","cell_type":"code","source":"# Text labels for scene description\nlabels = [\"busy city street\", \"traffic accident\", \"construction site\", \"empty road\"]","metadata":{},"outputs":[],"execution_count":null},{"id":"fb862902","cell_type":"code","source":"# Process inputs\ninputs = processor(text=labels, images=image, return_tensors=\"pt\", padding=True)","metadata":{},"outputs":[],"execution_count":null},{"id":"894ccaaf","cell_type":"code","source":"# Run inference\noutputs = model(**inputs)\nlogits = outputs.logits_per_image\nprobs = logits.softmax(dim=1).detach().numpy()","metadata":{},"outputs":[],"execution_count":null},{"id":"678e5d58","cell_type":"code","source":"# Print results\nfor label, prob in zip(labels, probs[0]):\n    print(f\"{label}: {prob:.4f}\")","metadata":{},"outputs":[],"execution_count":null}]}